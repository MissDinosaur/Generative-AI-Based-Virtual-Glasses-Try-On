{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9586a365",
   "metadata": {},
   "source": [
    "This notebook contains the kernal codes and funtions implementation. You can run below code cell directly to see the overlay result after typing into the selfie path and glasses url. \n",
    "\n",
    "Besides, you can also do the fine tunning or other modification here as it's quick to get feedback on notebook.\n",
    "\n",
    "#### Note\n",
    "1. Glasses image should be type of .png or .webp as this program needs glasses images have alpha channel. If The extension of galsses image is .jpg or .jepg, then this demo will not working.\n",
    "2. You can read demo/technical_document.md file to get ideas expalined in details and its python implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method BEST one\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import urllib.request\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_glasses_center(img_rgba: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the visual center point (C2) of a pair of glasses from an RGBA image.\"\"\"\n",
    "    alpha = img_rgba[:, :, 3]\n",
    "    ys, xs = np.where(alpha > 0)  \n",
    "\n",
    "    top, bottom = ys.min(), ys.max()\n",
    "    left, right = xs.min(), xs.max()\n",
    "\n",
    "    y_mid = top + (bottom - top) / 2  # Upper one-third line\n",
    "\n",
    "    # Left lens\n",
    "    is_left = xs < (left + right) / 2 # Identifies which pixels belong to the left half of the frame.\n",
    "    pts_l = np.vstack([xs[is_left], ys[is_left]]).T\n",
    "    pts_l_top = pts_l[pts_l[:,1] < top + (bottom - top)*0.4]\n",
    "    # Calculates the average point (center) of the left lens top area.\n",
    "    C_left = pts_l_top.mean(axis=0) if len(pts_l_top)>0 else np.array([left, y_mid])\n",
    "\n",
    "    # Right lens\n",
    "    is_right = ~is_left\n",
    "    pts_r = np.vstack([xs[is_right], ys[is_right]]).T\n",
    "    pts_r_top = pts_r[pts_r[:,1] < top + (bottom - top)*0.4]\n",
    "    C_right = pts_r_top.mean(axis=0) if len(pts_r_top)>0 else np.array([right, y_mid])\n",
    "\n",
    "    return (C_left + C_right) / 2  # float center of the frame\n",
    "\n",
    "def remove_lens_region(img_rgba: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Removes the glasses' lens region from an RGBA image by setting those areas to transparent (alpha = 0),\n",
    "    while preserving the frame and other regions.\n",
    "    \"\"\"\n",
    "    # Check if the image contains an alpha channel\n",
    "    if img_rgba.shape[2] != 4:\n",
    "        print(\"Warning: Image has no alpha channel. Skipping processing.\")\n",
    "        return img_rgba\n",
    "\n",
    "    # Extract the alpha channel\n",
    "    alpha = img_rgba[:, :, 3]\n",
    "\n",
    "    # Convert image from BGRA to BGR\n",
    "    rgb = cv2.cvtColor(img_rgba, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    # Convert image from BGR to HSV color space\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define lens color range and create mask\n",
    "    # H: 0~180 means accepting all the hues\n",
    "    # S: 0~30 means low saturation, close to gray-white, with a high level of transparentcy and lens highlight\n",
    "    # V: 200~255 means highlight area (eg, refective lens)\n",
    "    # This detects very bright, low-saturation areas â€” typical of reflective or transparent lens zones.\n",
    "    # Because Lens regions usually appear light-colored or whitish, which have: Low Saturation (S) and High Brightness (V)\n",
    "    # Temple arms that appear inside the lens will often be captured too, because they become lighter when overlaid on bright lenses.\n",
    "    lower_bound = np.array([0, 0, 200])\n",
    "    upper_bound = np.array([180, 30, 255])\n",
    "    mask_lens = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "    # Use morphological operations to remove small noise\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_lens = cv2.morphologyEx(mask_lens, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Find contours of the lens region\n",
    "    contours, _ = cv2.findContours(mask_lens, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a fully transparent mask with the same size as the original alpha channel\n",
    "    transparent_mask = np.zeros_like(alpha, dtype=np.uint8)\n",
    "\n",
    "    # Compute the convex hull for each contour and fill the transparent mask\n",
    "    # Convex hull smooths out the lens region, removing dents and gaps (such as small structures of temple arms).\n",
    "    # This ensures a solid transparent lens area, without leftover bits inside.\n",
    "    for contour in contours:\n",
    "        convex_hull = cv2.convexHull(contour)\n",
    "        cv2.fillPoly(transparent_mask, [convex_hull], 255)\n",
    "\n",
    "    # Apply the transparent mask to the alpha channel to make the lens region transparent\n",
    "    # If transparent_mask == 255, i.e., this pixel is in the lens region, then set alpha=0; else keep original alpha value\n",
    "    img_rgba[:, :, 3] = np.where(transparent_mask == 255, 0, alpha)\n",
    "\n",
    "    return img_rgba\n",
    "\n",
    "def rotate_galsses_image(img_rgba: np.ndarray, angle) -> np.ndarray:\n",
    "    (h, w) = img_rgba.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    return cv2.warpAffine(img_rgba, M, (w, h), flags=cv2.INTER_LINEAR,\n",
    "                          borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0,0))\n",
    "\n",
    "def rotate_pt(pt, center, angle):\n",
    "    \"\"\" This function rotates a 2D point pt around a given center by a given angle (in degrees) \"\"\"\n",
    "    ang = np.deg2rad(angle)\n",
    "    # Builds a 2D rotation matrix\n",
    "    R = np.array([[np.cos(ang), -np.sin(ang)],\n",
    "                  [np.sin(ang),  np.cos(ang)]])\n",
    "    return (R.dot(pt - center) + center)\n",
    "\n",
    "# ---------- STEP3: Detect keypoints using MediaPipe ----------\n",
    "def line_intersection(point_1, line_vec_1, point_2, line_vec_2):\n",
    "    \"\"\"Compute intersection point of two lines\"\"\"\n",
    "    A = np.array([line_vec_1, -line_vec_2]).T\n",
    "    if np.linalg.matrix_rank(A) < 2:\n",
    "        return (point_1 + point_2) / 2  # fallback\n",
    "    b = point_2 - point_1\n",
    "    t_s = np.linalg.solve(A, b)\n",
    "    return point_1 + t_s[0] * line_vec_1\n",
    "\n",
    "def get_keypoints(face_img: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Use MediaPipe to detect facial landmarks\n",
    "    and calculate useful points for positioning glasses\n",
    "    in a virtual try-on system.\n",
    "    \"\"\"\n",
    "    mp_face = mp.solutions.face_mesh\n",
    "    FACE_LMS = mp_face.FaceMesh(static_image_mode=True)\n",
    "\n",
    "    h, w = face_img.shape[:2]\n",
    "    res = FACE_LMS.process(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))\n",
    "    # If no face landmarks were detected, raise an error.\n",
    "    if not res.multi_face_landmarks:\n",
    "        raise ValueError(\"No face detected\")\n",
    "    # Get the face's landmarks.\n",
    "    lm = res.multi_face_landmarks[0]\n",
    "\n",
    "    def pt(i): return np.array([lm.landmark[i].x * w, lm.landmark[i].y * h])\n",
    "\n",
    "    # Eye centers\n",
    "    L_eye_center = (pt(33) + pt(133)) / 2\n",
    "    R_eye_center = (pt(362) + pt(263)) / 2\n",
    "\n",
    "    # Nose bridge: tip and root\n",
    "    nose_tip = pt(1)\n",
    "    nose_root = pt(168)\n",
    "    nose_center = (nose_tip + nose_root) / 2 # the midpoint between tip and root (used as a helper point).\n",
    "\n",
    "    # Eye line vector\n",
    "    eye_line_vec = R_eye_center - L_eye_center\n",
    "    eye_line_point = L_eye_center\n",
    "\n",
    "    # Nose bridge line vector\n",
    "    nose_vec = nose_tip - nose_root\n",
    "    nose_point = nose_center\n",
    "\n",
    "    # Compute intersection point of the eye_line_vec and nose_vec as face center C1\n",
    "    C1 = line_intersection(eye_line_point, eye_line_vec, nose_point, nose_vec)\n",
    "\n",
    "    return {\n",
    "        'L_eye': L_eye_center,\n",
    "        'R_eye': R_eye_center,\n",
    "        'L_ear': pt(234),\n",
    "        'R_ear': pt(454),\n",
    "        'C1': C1\n",
    "    }\n",
    "\n",
    "def overlay_images(gl2: np.ndarray, face: np.ndarray, x: int, y: int):\n",
    "    \"\"\" \n",
    "    Overlay the RGBA glasses image gl2 onto the face image at position (x, y).\n",
    "    gl2: The transformed (scaled + rotated) glasses image with alpha channel.\n",
    "    face: The original face image (typically BGR or RGB, no alpha).\n",
    "    x, y: The top-left coordinates where the glasses should be placed.\n",
    "    \"\"\"\n",
    "    h2, w2 = gl2.shape[:2]\n",
    "\n",
    "    out = face.copy() # Creates a copy of the face image to avoid modifying the original.\n",
    "    galsses = gl2\n",
    "    fg = galsses[:, :, 3] / 255   # foreground mask\n",
    "\n",
    "    # Crop to avoid out-of-bounds\n",
    "    H, W = out.shape[:2]\n",
    "    x1 = max(x, 0)\n",
    "    y1 = max(y, 0)\n",
    "    x2 = min(x + w2, W)\n",
    "    y2 = min(y + h2, H)\n",
    "\n",
    "    ox1 = x1 - x\n",
    "    oy1 = y1 - y\n",
    "    ox2 = ox1 + (x2 - x1)\n",
    "    oy2 = oy1 + (y2 - y1)\n",
    "\n",
    "    for c in range(3):\n",
    "        out[y1:y2, x1:x2, c] = fg[oy1:oy2, ox1:ox2] * galsses[oy1:oy2, ox1:ox2, c] + \\\n",
    "                               (1 - fg[oy1:oy2, ox1:ox2]) * out[y1:y2, x1:x2, c]\n",
    "    return out\n",
    "\n",
    "def smooth_frame_edge(img_rgba: np.ndarray,\n",
    "                      white_thresh: int = 220,\n",
    "                      alpha_thresh: int = 150,\n",
    "                      kernel_size: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Strongly clean white fringe and semi-transparent noisy edges on thin glasses frames, making frames smoother.\n",
    "    \"\"\"\n",
    "    if img_rgba.shape[2] != 4:\n",
    "        return img_rgba\n",
    "\n",
    "    result = img_rgba.copy()\n",
    "    rgb = result[:, :, :3]\n",
    "    alpha = result[:, :, 3]\n",
    "\n",
    "    # Step 1: Detect low-alpha fringe region\n",
    "    fringe_mask = np.logical_and(\n",
    "        alpha < alpha_thresh,\n",
    "        np.all(rgb > white_thresh, axis=2)\n",
    "    ).astype(np.uint8) * 255\n",
    "\n",
    "    # Step 2: Morphological open to refine mask\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    refined_mask = cv2.morphologyEx(fringe_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Step 3: Apply refined mask: set those pixels fully transparent\n",
    "    result[refined_mask == 255] = [0, 0, 0, 0]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------------- Main function for try-on ----------------\n",
    "def main_tryon(selfie_path: str, glasses_url: str, gl_base_sacle_param: float = 1.5, gl_upward_pixels: int =10):\n",
    "    \"\"\"_summary_\n",
    "    selfie_path: image path of selfie\n",
    "    glasses_url: image url of glasses\n",
    "    gl_base_sacle_param: the base scale amount which glasses are resized at, defaults to 1.5\n",
    "    gl_upward_pixels: the pixels value which glasses are moved upforward, defaults to 10\n",
    "    \"\"\"\n",
    "    # ---------- STEP1: Load selfie and frame ----------\n",
    "    # Load selfie\n",
    "    face = cv2.imread(selfie_path)  # (H, W, 3)\n",
    "    # Visualize selfie\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(2,2,1)    \n",
    "    plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Selfie')\n",
    "    # cv2_imshow(face)\n",
    "\n",
    "    # Load glasses from URL directly\n",
    "    resp = urllib.request.urlopen(glasses_url)\n",
    "    img_array = np.asarray(bytearray(resp.read()), dtype=np.uint8)\n",
    "    gl = cv2.imdecode(img_array, cv2.IMREAD_UNCHANGED)  # (H, W, 4)\n",
    "    \n",
    "    # Visualize the glasses\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(cv2.cvtColor(gl, cv2.COLOR_BGRA2RGBA))\n",
    "    plt.title('Glasses image')\n",
    "    # cv2_imshow(gl)\n",
    "\n",
    "\n",
    "    # ---------- STEP2 Detect face keypoints using MediaPipe ----------\n",
    "    # Calculate keypoints\n",
    "    kp = get_keypoints(face)\n",
    "    C1 =  kp['C1']  # Get the center of the face\n",
    "    ear_dist = np.linalg.norm(kp['R_ear'] - kp['L_ear'])\n",
    "    # Get the angle at which the selfie tilts\n",
    "    angle = np.degrees(np.arctan2(kp['R_eye'][1] - kp['L_eye'][1],\n",
    "                                  kp['R_eye'][0] - kp['L_eye'][0]))\n",
    "\n",
    "\n",
    "    # ---------- STEP3: Make the frame lens transparent ----------\n",
    "    gl = remove_lens_region(gl)\n",
    "    gl = smooth_frame_edge(gl, white_thresh=200, alpha_thresh=180, kernel_size=2) # This effect of this function is not good\n",
    "\n",
    "\n",
    "    # ---------- STEP4: Resize and rotate the frame relative to the face ----------\n",
    "    # Compute the frame center; And scale, rotate frame\n",
    "    C2 = compute_glasses_center(gl)\n",
    "    scale = (ear_dist * gl_base_sacle_param) / gl.shape[1]\n",
    "    # Resizes the glasses image gl by scale in both width and height.\n",
    "    gl2 = cv2.resize(gl, (0,0), fx=scale, fy=scale)\n",
    "\n",
    "    # a negative angle means clockwise rotation.\n",
    "    gl2 = rotate_galsses_image(gl2, -angle)\n",
    "\n",
    "\n",
    "    # ---------- STEP5: Overlay frame onto face ----------\n",
    "    # Align frame center C2 with face center C1\n",
    "    h2, w2 = gl2.shape[:2]\n",
    "    rel = C2 * scale  # Scales the original glasses center C2 by the same factor as the image.\n",
    "    # Rotates the scaled glasses center point rel around the center of the rotated image.\n",
    "    C2r = rotate_pt(rel, np.array([w2/2, h2/2]), -angle)\n",
    "    top_left = C1 - C2r\n",
    "    top_left[1] -= gl_upward_pixels  # Shift upward some pixels (10 pixels by default) to avoid covering eyes, for a more realistic effect.\n",
    "    x, y = int(top_left[0]), int(top_left[1])\n",
    "\n",
    "    # Overlay the transformed glasses gl2 on top of the face image at coordinates (x, y).\n",
    "    out = overlay_images(gl2, face, x, y)\n",
    "    \n",
    "    # ---------- STEP6: Display and save results ----------\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(cv2.cvtColor(out, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Try-on result')\n",
    "    plt.show()\n",
    "    #cv2_imshow(out) # works in Google Colab\n",
    "    print(\"Virtual Try On Done!\")\n",
    "    \n",
    "\n",
    "# ---------- Demo here ----------\n",
    "# Get the glasses urls from given PostgreSQL table (column: main_image)\n",
    "glasses_urls = [\n",
    "    \"https://optiker-bode.de/sites/default/files/2022-10/0RX4378V__8172_000A.png\",\n",
    "    \"https://optiker-bode.de/sites/default/files/2022-10/0RX6448__3086_000A.png\",\n",
    "    \"https://optiker-bode.de/sites/default/files/2024-04/0RX6466__2904_000A.png\",\n",
    "    \"https://optiker-bode.de/sites/default/files/2021-07/0RX1972V__2943_000A.png\",\n",
    "    \"https://optiker-bode.de/sites/default/files/2021-07/0RX6536__3086_000A.png\",\n",
    "    \"https://optiker-bode.de/sites/default/files/2021-08/0RX3582V__2946_000A.png\",\n",
    "    \"https://optiker-bode.de/sites/default/files/2021-08/0RX5380__5947_000A.png\"\n",
    "]\n",
    "\n",
    "# Replace these with your selfie paths\n",
    "selfie_paths = [\n",
    "  \"/content/drive/MyDrive/virtual_tryon/selfies/CM200.jpg\",\n",
    "  \"/content/drive/MyDrive/virtual_tryon/selfies/CM246.jpg\",\n",
    "  \"/content/drive/MyDrive/virtual_tryon/selfies/CF537.jpg\",\n",
    "  \"/content/drive/MyDrive/virtual_tryon/selfies/CF252.jpg\",\n",
    "  \"/content/drive/MyDrive/virtual_tryon/selfies/AF108.jpg\",\n",
    "  \"/content/drive/MyDrive/virtual_tryon/selfies/AM421.jpg\",\n",
    "  \"/content/drive/MyDrive/virtual_tryon/selfies/CF8.jpg\"\n",
    "]\n",
    "\n",
    "selfie = \"D:/xxx/genai-virtual-glasses-tryon/data/selfies/SCUT-FBP5500_v2/AF805.jpg\" # selfie_paths[6]\n",
    "gl_url = \"https://optiker-bode.de/sites/default/files/2024-05/F_4549567221023_000.jpeg\" # glasses_urls[0]\n",
    "main_tryon(selfie, gl_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
